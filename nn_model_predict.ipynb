{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test_input_paths, version_nr): \n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    export_path_base = \"./checkpoint_dir\"\n",
    "    export_path = os.path.join(tf.compat.as_bytes(export_path_base),\n",
    "                               tf.compat.as_bytes(str(version_nr)))\n",
    "    \n",
    "    # IMPORTANT: All keys below need to be the same with the one used when saving\n",
    "    init_iterator_signature_key = 'init_iterator_key'\n",
    "    input_key_filenames = 'filenames'\n",
    "    predict_signature_key = 'predict_classes_key'    \n",
    "    input_key_training = 'training'\n",
    "    output_key_input_IDs = 'input_IDs'\n",
    "    output_key_X_mb = 'X_mb'\n",
    "    output_key_Y_mb = 'Y_mb'\n",
    "    output_key_predictions = 'predictions'\n",
    "    \n",
    "    prediction_results_file_name = \"v\" + str(version_nr) + \"_prediction_results.csv\"\n",
    "    column_names = ['input_ID', 'prediction result', 'Y (actual labels)']\n",
    "    raw_data = {column_names[0]: [], \n",
    "                column_names[1]: [],\n",
    "                column_names[2]: []}\n",
    "    df = pd.DataFrame(raw_data, columns = column_names)\n",
    "    df.to_csv(prediction_results_file_name, index=False)    \n",
    "    \n",
    "    with tf.Session() as sess_predict:\n",
    "        \n",
    "        meta_graph_def = tf.saved_model.loader.load(sess_predict,\n",
    "                                                    [tf.saved_model.tag_constants.SERVING],\n",
    "                                                    export_path)\n",
    "        signature = meta_graph_def.signature_def\n",
    "\n",
    "        # Get tensor namesby using corresponding tensor keys\n",
    "        filenames_tensor_name = signature[init_iterator_signature_key].inputs[input_key_filenames].name\n",
    "        training_tensor_name = signature[predict_signature_key].inputs[input_key_training].name\n",
    "        input_IDs_tensor_name = signature[predict_signature_key].outputs[output_key_input_IDs].name\n",
    "        X_mb_tensor_name = signature[predict_signature_key].outputs[output_key_X_mb].name\n",
    "        Y_mb_tensor_name = signature[predict_signature_key].outputs[output_key_Y_mb].name\n",
    "        predictions_tensor_name = signature[predict_signature_key].outputs[output_key_predictions].name\n",
    "        \n",
    "        # Get actual tensors by using tensor names\n",
    "        filenames_tensor = sess_predict.graph.get_tensor_by_name(filenames_tensor_name)\n",
    "        training_tensor = sess_predict.graph.get_tensor_by_name(training_tensor_name)\n",
    "        input_IDs_tensor = sess_predict.graph.get_tensor_by_name(input_IDs_tensor_name)\n",
    "        X_mb_tensor = sess_predict.graph.get_tensor_by_name(X_mb_tensor_name)\n",
    "        Y_mb_tensor = sess_predict.graph.get_tensor_by_name(Y_mb_tensor_name)\n",
    "        predictions_tensor = sess_predict.graph.get_tensor_by_name(predictions_tensor_name)\n",
    "    \n",
    "        # Initialize file iterator to read the test data from the csv file\n",
    "        sess_predict.run(signature[init_iterator_signature_key].method_name, \n",
    "                         feed_dict={filenames_tensor: test_input_paths})\n",
    "        with open(prediction_results_file_name, 'a') as file:\n",
    "            while True:\n",
    "                try:\n",
    "                  # Read the test csv file and make predictions\n",
    "                  input_IDs, X_mb, Y_mb, predictions = sess_predict.run([input_IDs_tensor, \n",
    "                                                                         X_mb_tensor, \n",
    "                                                                         Y_mb_tensor,\n",
    "                                                                         predictions_tensor], \n",
    "                                                                         feed_dict={training_tensor: False})\n",
    "\n",
    "                  #print(\"input_IDs: \\n\", input_IDs)\n",
    "                  #print(\"X_mb: \\n\", X_mb)\n",
    "                  #print(\"Y_mb: \\n\", Y_mb)\n",
    "                  #print(\"predictions: \\n\", predictions)\n",
    "                  raw_data = {column_names[0]: input_IDs, \n",
    "                              column_names[1]: predictions,\n",
    "                              column_names[2]: Y_mb.tolist()}\n",
    "                  df = pd.DataFrame(raw_data, columns = column_names)\n",
    "                  df.to_csv(file, header=False, index=False)\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                  print(\"All examples in the test file(s) have been processed\")\n",
    "                  break         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'./checkpoint_dir/80/variables/variables'\n",
      "All examples in the test file(s) have been processed\n"
     ]
    }
   ],
   "source": [
    "test_path1 = \"test1.csv\"\n",
    "test_input_paths = [test_path1]\n",
    "\n",
    "version_nr = 80\n",
    "\n",
    "make_predictions(test_input_paths, version_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "aa = np.array([[1, 2, 3], [4, 5,6]])\n",
    "\n",
    "print(aa.shape)\n",
    "print(aa[:,-1])\n",
    "print(aa[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = np.array([[0], [0], [1]])\n",
    "print(bb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
