{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters and optimization parameters\n",
    "\n",
    "########################################\n",
    "# Train/Dev/Test data may reside in several files.\n",
    "train_path1 = \"train1.csv\"\n",
    "train_path2 = \"train2.csv\"\n",
    "dev_path1 = \"dev1.csv\"\n",
    "test_path1 = \"test1.csv\"\n",
    "TRAIN_INPUT_PATHS = [train_path1, train_path2]\n",
    "DEV_INPUT_PATHS = [dev_path1]\n",
    "TEST_INPUT_PATHS = [test_path1]\n",
    "\n",
    "# UPDATE-1 IN EACH PROJECT (depending on default values for each column)\n",
    "# Determine default values for each column in case data is missing\n",
    "RECORD_DEFAULTS = [[\"\"], [0.0], [0.0], [0.0], [0.0], [0.0], [0]]\n",
    "\n",
    "NUM_FEATURES = len(RECORD_DEFAULTS) - 2\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# LEARNING RATE (alpha) related settings\n",
    "INITIAL_LEARNING_RATE = 0.03\n",
    "\n",
    "# LEARNING DECAY settings\n",
    "DECAY_STEPS = 10      # After this many steps, learning_rate will be = learning_rate * decay_rate\n",
    "DECAY_RATE = 1.       # if decay_rate=1.  then it means learning decay is not applied\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# GENERAL model params\n",
    "NUM_TRAIN_EPOCHS = 80      # Let this be a multiple of EPOCH_PERIOD_TO_SAVE_COST\n",
    "MINIBATCH_SIZE = 8\n",
    "EPOCH_PERIOD_TO_SAVE_COST = DECAY_STEPS   # After how many epochs do you want to save cost & accuracy?\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# NN Architecture\n",
    "NUM_CLASSES = 2\n",
    "NUM_UNITS_IN_LAYERS = [NUM_FEATURES, 6, NUM_CLASSES] \n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# DROPOUT settings\n",
    "NO_DROPOUT_IN_INPUT_LAYER = 0.   # Setting the layer dropout_rate=0 will deactivate dropout in that layer\n",
    "NO_DROPOUT_IN_OUTPUT_LAYER = 0.\n",
    "# You only apply dropout in hidden layers. E.g. if rate=0.1 for a layer, 0.1 of units in that layer is dropped out\n",
    "DROPOUT_RATES_PER_LAYER = [NO_DROPOUT_IN_INPUT_LAYER, 0., NO_DROPOUT_IN_OUTPUT_LAYER]    \n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# REGULARIZATION settings\n",
    "LAMBD = 0.     # regularization parameter lambda\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# BATCH NORMALIZATION settings - also helps regularizing\n",
    "NORMALIZE_BATCH = True\n",
    "MOVING_AVG_MOMENTUM = 0.99   # irrelevant if NORMALIZE_BATCH = False\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# INPUT (LAYER) NORMALIZATION\n",
    "NORMALIZE_INPUT = True\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# Utils\n",
    "PRINT_PROGRESS = True\n",
    "SAVE_MODEL = False\n",
    "########################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Returns the tf variable if exists. Otherwise creates a new one.\n",
    "# Example call:   tf_variable = get_tf_variable(...)\n",
    "def get_nn_weights(variable_scope, variable_name, dim1, dim2):\n",
    "    '''\n",
    "    Used to retrieve or create new NN parameters (weights & biases)\n",
    "    When calling, the corresponding NNparameter's dimensions need to be specified too.\n",
    "    Returns a tensorflow variable. Note that NN parameters need to be tensorflow variables\n",
    "    so that values can be changed whenever needed when training. Also note that it is \n",
    "    explicitly defined that the created variable is TRAINABLE.\n",
    "    '''\n",
    "    with tf.variable_scope(variable_scope, reuse=tf.AUTO_REUSE):\n",
    "      weights = tf.get_variable(variable_name, \n",
    "                                [dim1, dim2], \n",
    "                                trainable=True, \n",
    "                                initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Returns the tf variable if exists. Otherwise creates a new one.\n",
    "# Example call:   tf_variable = get_tf_variable(...)\n",
    "def get_nn_biases(variable_scope, variable_name, dim1, dim2):\n",
    "    '''\n",
    "    Used to retrieve or create new NN parameters (weights & biases)\n",
    "    When calling, the corresponding NNparameter's dimensions need to be specified too.\n",
    "    Returns a tensorflow variable. Note that NN parameters need to be tensorflow variables\n",
    "    so that values can be changed whenever needed when training. Also note that it is \n",
    "    explicitly defined that the created variable is TRAINABLE.\n",
    "    '''\n",
    "    with tf.variable_scope(variable_scope, reuse=tf.AUTO_REUSE):\n",
    "      biases = tf.get_variable(variable_name, \n",
    "                                [dim1, dim2], \n",
    "                                trainable=(not NORMALIZE_BATCH), \n",
    "                                initializer = tf.zeros_initializer())\n",
    "    return biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NN params before starting the training\n",
    "def initialize_layer_parameters():\n",
    "    '''\n",
    "    Exmaple return: parameters = {\"W1\": tf_variable_for_W1, \"b1\": tf_variable_for_b1, ...}\n",
    "    '''\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(NUM_UNITS_IN_LAYERS)\n",
    "     \n",
    "    for i in range (1, L):\n",
    "        #print(\"W\" + str(i) + \" \" + str(NUM_UNITS_IN_LAYERS[i]) + \" \" + str(NUM_UNITS_IN_LAYERS[i-1]))\n",
    "        temp_weight = get_nn_weights(\"weights\",\n",
    "                                     \"W\"+str(i), \n",
    "                                     NUM_UNITS_IN_LAYERS[i], \n",
    "                                     NUM_UNITS_IN_LAYERS[i-1])\n",
    "        parameters.update({\"W\" + str(i) : temp_weight})  \n",
    "        \n",
    "        #print(\"b\" + str(i) + \" \" + str(NUM_UNITS_IN_LAYERS[i]) + \" \" + str(1))\n",
    "        temp_bias = get_nn_biases(\"biases\",\n",
    "                                  \"b\"+str(i), \n",
    "                                  NUM_UNITS_IN_LAYERS[i], \n",
    "                                  1)\n",
    "        parameters.update({\"b\" + str(i) : temp_bias})  \n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_with_relu(X, training):\n",
    "\n",
    "    # X has the shape (num_features, num_examples), where num_examples = MINIBATCH_SIZE\n",
    "    \n",
    "    L = len(NUM_UNITS_IN_LAYERS)\n",
    "\n",
    "    \n",
    "    if NORMALIZE_INPUT:\n",
    "        input_norm_mu = get_input_norm_parameter(\"input_norm_scope\", \n",
    "                                                 \"input_norm_mu\", \n",
    "                                                 1, NUM_FEATURES)\n",
    "        input_norm_sigma_square = get_input_norm_parameter(\"input_norm_scope\", \n",
    "                                                           \"input_norm_sigma_square\", \n",
    "                                                           1, NUM_FEATURES)        \n",
    "        X = tf.divide(tf.subtract(X, input_norm_mu), \n",
    "                      input_norm_sigma_square)\n",
    "    \n",
    "    A_temp = tf.transpose(X)\n",
    "    \n",
    "    for i in range (1, L):\n",
    "        W = get_nn_weights(\"weights\",\n",
    "                           \"W\"+str(i), \n",
    "                           NUM_UNITS_IN_LAYERS[i], \n",
    "                           NUM_UNITS_IN_LAYERS[i-1])\n",
    "\n",
    "        b = get_nn_biases(\"biases\",\n",
    "                          \"b\"+str(i), \n",
    "                          NUM_UNITS_IN_LAYERS[i], \n",
    "                          1)\n",
    "\n",
    "        Z_temp = tf.add(tf.matmul(W, A_temp), b)\n",
    "        if NORMALIZE_BATCH:\n",
    "            if (i < (L-1)):    # Do NOT batch normalize the output layer \n",
    "                with tf.variable_scope(\"batch_norm_scope_layer_\"+str(i), reuse=tf.AUTO_REUSE):\n",
    "                    Z_temp = tf.layers.batch_normalization(Z_temp, axis=0, \n",
    "                                                           training=training,\n",
    "                                                           momentum=MOVING_AVG_MOMENTUM,\n",
    "                                                           name='normalize_batch_layer_'+str(i))\n",
    "\n",
    "        A_temp = tf.nn.relu(Z_temp)\n",
    "        if (i < (L-1)):     # Do NOT apply dropout in output layer\n",
    "            A_temp = tf.layers.dropout(A_temp, rate=DROPOUT_RATES_PER_LAYER[i], training=training)\n",
    "            \n",
    "    batch_predictions = tf.argmax(Z_temp, 0, name=\"batch_predicted_classes\")\n",
    "\n",
    "    return batch_predictions, Z_temp   #This is the linear output of last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION\n",
    "# This function requires update if softmax is not used in the output layer\n",
    "def compute_cost(ZL, Y):\n",
    "    \"\"\"\n",
    "    This function should be used for multinomial mutually exclusive classification, i.e. pick one out of N classes. \n",
    "    Also applicable when N = 2.\n",
    "    The labels must be one-hot encoded or can contain soft class probabilities: a particular example can belong to\n",
    "    class A with 50% probability and class B with 50% probability. Note that strictly speaking it doesn't mean that\n",
    "    it belongs to both classes, but one can interpret the probabilities this way.\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "\n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(ZL)      # ZL.shape = (num_features x MINIBATCH_SIZE)\n",
    "    labels = tf.squeeze(tf.one_hot(Y, NUM_CLASSES), 1)\n",
    "    \n",
    "    # This cost calculation is unregularized. cost = (1/m) sum(Loss(y_hat(i), y(i))), where i = 1,..,mb_size \n",
    "    #tf.reduce_mean(..) function finds the mean of costs of examples in the given mini-batch\n",
    "    cost_unregularized = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = labels))\n",
    "    \n",
    "    # Add L2 regularization: cost += (LAMBD / (2 * MINIBATCH_SIZE)) * sum(W(i,j)**2), \n",
    "    # where i:1,..,n[l] and j:1,..,n[l-1] \n",
    "    # L:number of layers (except input layer). \n",
    "    L = len(NUM_UNITS_IN_LAYERS)\n",
    "    \n",
    "    # The list will have L elements, each holding the sum of weight matrix values in each layer. Later, these\n",
    "    # weight values need to be summed up again\n",
    "    list_sum_weights = []\n",
    "    \n",
    "    for i in range (1, L):\n",
    "        W = get_nn_weights(\"weights\",\n",
    "                           \"W\"+str(i), \n",
    "                           NUM_UNITS_IN_LAYERS[i], \n",
    "                           NUM_UNITS_IN_LAYERS[i-1])\n",
    "        list_sum_weights.append(tf.nn.l2_loss(W))\n",
    "    \n",
    "    # in the following calculation, since the l2_loss returns \"sum(t ** 2) / 2\", where the sum of squares is already\n",
    "    # divided by 2, there is no need to bultiply the mb_size with 2\n",
    "    #regularization_effect = (LAMBD / MINIBATCH_SIZE) * sum(list_sum_weights)\n",
    "    regularization_effect = tf.multiply((LAMBD / MINIBATCH_SIZE), tf.add_n(list_sum_weights))\n",
    "    cost = tf.add(cost_unregularized, regularization_effect)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Returns the input normalization parameter mu / sigma_square.\n",
    "# IF the variable does not exist, it creates a new one.\n",
    "\n",
    "def get_input_norm_parameter(variable_scope, variable_name, dim1, dim2):\n",
    "\n",
    "    with tf.variable_scope(variable_scope, reuse=tf.AUTO_REUSE):\n",
    "      input_norm_var = tf.get_variable(variable_name, \n",
    "                                       [dim1, dim2], \n",
    "                                       trainable=False, \n",
    "                                       initializer = tf.ones_initializer())\n",
    "    return input_norm_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive data from csv file\n",
    "\n",
    "def decode_csv(line):\n",
    "    parsed_line = tf.decode_csv(line, RECORD_DEFAULTS)\n",
    "    label = parsed_line[-1:]          # last column is labels\n",
    "    input_id = parsed_line[0]\n",
    "    del parsed_line[-1]               # delete the last element from the list   (label column)\n",
    "    del parsed_line[0]                # even delete the first element bcz it is assumed NOT to be a feature\n",
    "    input_id = tf.stack(input_id)\n",
    "    features = tf.stack(parsed_line)  # Stack features so that you can later vectorize forward prop., etc.\n",
    "    label = tf.stack(label)           # Needed bcz labels consist of 2 columns\n",
    "    batch_to_return = input_id, features, label\n",
    "\n",
    "    return batch_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(..) stores/saves the trained model.\n",
    "\n",
    "# IMPORTANT: All given keys below (e.g. 'filenames', 'training', 'input_IDs', 'init_iterator_key', \n",
    "# etc.) need to be remembered in the prediction file to be able to load the correct tensors when\n",
    "# loading the graph.\n",
    "\n",
    "def save_model(epoch_nr, tensor_info_filenames, tensor_info_training, tensor_info_input_IDs, \n",
    "               tensor_info_X_mb, tensor_info_Y_mb, tensor_info_predictions, init_iterator):\n",
    "\n",
    "    export_path_base = \"./checkpoint_dir\"\n",
    "    export_path = os.path.join(tf.compat.as_bytes(export_path_base),\n",
    "                               tf.compat.as_bytes(str(epoch_nr)))\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "    \n",
    "    # To be used (in the prediction program) to initialize file iterator to read samples\n",
    "    # for which predictions will be done\n",
    "    init_iterator_signature = (\n",
    "    tf.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs={'filenames': tensor_info_filenames},\n",
    "        method_name=init_iterator.name))\n",
    "    \n",
    "    # This signature will be used when \"predicting\". We are only interested in \"predictions\"\n",
    "    # but it is good to gather corresponding input_IDs, X_mini_batch (features), and\n",
    "    # Y_mini_batch (actual labels)\n",
    "    prediction_signature = (\n",
    "        tf.saved_model.signature_def_utils.build_signature_def(\n",
    "            inputs={'training': tensor_info_training},\n",
    "            outputs={'input_IDs': tensor_info_input_IDs,\n",
    "                     'X_mb': tensor_info_X_mb,\n",
    "                     'Y_mb': tensor_info_Y_mb,\n",
    "                     'predictions': tensor_info_predictions},\n",
    "            method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        tf.get_default_session(), \n",
    "        [tf.saved_model.tag_constants.SERVING],\n",
    "        signature_def_map={'init_iterator_key': init_iterator_signature,\n",
    "                           'predict_classes_key': prediction_signature}) \n",
    "\n",
    "    builder.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(mu, sigma_square):\n",
    "    \"\"\"\n",
    "    Returns NN parameters after the completion of training.\n",
    "    \"\"\"\n",
    "\n",
    "    tf.reset_default_graph()     # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)       # tf.reset_default_graph() needs to be run first before \n",
    "                                # calling tf.set_random_seed(..)\n",
    "    \n",
    "    costs_train = []                            \n",
    "    accuracies_train = []\n",
    "    costs_dev = []\n",
    "    accuracies_dev = []\n",
    "    precision_per_class = [0.] * NUM_CLASSES\n",
    "    update_precision_per_class = [[]] * NUM_CLASSES\n",
    "    recall_per_class = [0.] * NUM_CLASSES\n",
    "    update_recall_per_class = [[]] * NUM_CLASSES\n",
    "    f1_score_per_class = [0.] * NUM_CLASSES\n",
    "\n",
    "    training = tf.placeholder(tf.bool)    \n",
    "\n",
    "\n",
    "\n",
    "    with tf.name_scope(\"set_input_norm_params\"):\n",
    "        input_norm_mu = get_input_norm_parameter(\"input_norm_scope\", \n",
    "                                                 \"input_norm_mu\", \n",
    "                                                 1, NUM_FEATURES)\n",
    "        input_norm_sigma_square = get_input_norm_parameter(\"input_norm_scope\", \n",
    "                                                           \"input_norm_sigma_square\", \n",
    "                                                           1, NUM_FEATURES)    \n",
    "    \n",
    "        set_input_norm_mu = tf.multiply(input_norm_mu, \n",
    "                                        mu, \n",
    "                                        name=\"set_input_norm_mu\")\n",
    "        set_input_norm_sigma_square = tf.multiply(input_norm_sigma_square, \n",
    "                                                  sigma_square, \n",
    "                                                  name=\"set_input_norm_sigma_square\")\n",
    "    \n",
    "    with tf.name_scope(\"init_nn_params\"):\n",
    "        # Initialize parameters\n",
    "        parameters = initialize_layer_parameters()    \n",
    "\n",
    "    with tf.name_scope(\"next_train_batch\"):\n",
    "        filenames = tf.placeholder(tf.string, shape=[None])\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "        dataset = dataset.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv))\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "        dataset = dataset.batch(MINIBATCH_SIZE)\n",
    "        iterator = dataset.make_initializable_iterator()\n",
    "        input_IDs, X_mini_batch, Y_mini_batch = iterator.get_next()\n",
    "\n",
    "    with tf.name_scope(\"forward_prop\"):\n",
    "        # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "        batch_predictions, ZL = forward_propagation_with_relu(X_mini_batch, training)\n",
    "\n",
    "    with tf.name_scope(\"calc_cost\"):\n",
    "        # Cost function: Add cost function to tensorflow graph\n",
    "        cost_mini_batch = compute_cost(ZL, Y_mini_batch) \n",
    "\n",
    "    with tf.name_scope(\"learning_decay_scope\"):\n",
    "        # Global_step to use for the decay computation. Must not be negative.\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                                   global_step, \n",
    "                                                   DECAY_STEPS,  \n",
    "                                                   DECAY_RATE,  # how much will alpha be decayed?\n",
    "                                                   staircase=False)        \n",
    "        \n",
    "    with tf.name_scope(\"train\"):\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):        \n",
    "            # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "            optimizer =  tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost_mini_batch,\n",
    "                                                                                        global_step=global_step)        \n",
    "    \n",
    "    with tf.name_scope(\"metric_accuracy\"):\n",
    "        # Define the metric and update operations\n",
    "        accuracy, accuracy_update = tf.metrics.accuracy(Y_mini_batch,\n",
    "                                                        batch_predictions)\n",
    "\n",
    "    with tf.name_scope(\"metric_precision_and_recall\"):\n",
    "        # Placeholders to take in batches of data\n",
    "        tf_labels = tf.placeholder(dtype=tf.int64, shape=[Y_mini_batch.shape[0], 1])\n",
    "        tf_predictions = tf.placeholder(dtype=tf.int64, shape=[batch_predictions.shape[0], ])         \n",
    "        # NUM_UNITS_IN_LAYERS[-1] gives number of classes\n",
    "        for k in range (NUM_CLASSES):\n",
    "            precision_per_class[k], update_precision_per_class[k] = tf.metrics.precision(tf_labels, \n",
    "                                                                                         tf_predictions,\n",
    "                                                                                         name=\"precision_class_\"+str(k))\n",
    "            recall_per_class[k], update_recall_per_class[k] = tf.metrics.recall(tf_labels, \n",
    "                                                                                tf_predictions,\n",
    "                                                                                name=\"recall_class_\"+str(k))    \n",
    "\n",
    "    with tf.name_scope(\"reset_metric_variables\"):\n",
    "        # Isolate the variables stored behind the scenes by the metric operation\n",
    "        accuracy_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=\"metric_accuracy\")\n",
    "        precision_and_recall_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, \n",
    "                                                      scope=\"metric_precision_and_recall\")\n",
    "        #recall_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=\"metric_recall\")\n",
    "        metrics_var_list = accuracy_vars + precision_and_recall_vars #+ recall_vars\n",
    "        # Define initializer to initialize/reset running variables\n",
    "        tf_metrics_vars_initializer = tf.variables_initializer(var_list=metrics_var_list) \n",
    "        \n",
    "    # List here the tensors that will be needed in the prediction program later on\n",
    "    with tf.name_scope(\"save_model_tensors\"):\n",
    "        tensor_info_filenames = tf.saved_model.utils.build_tensor_info(filenames)\n",
    "        tensor_info_training = tf.saved_model.utils.build_tensor_info(training)\n",
    "        tensor_info_input_IDs = tf.saved_model.utils.build_tensor_info(input_IDs)\n",
    "        tensor_info_X_mb = tf.saved_model.utils.build_tensor_info(X_mini_batch)\n",
    "        tensor_info_Y_mb = tf.saved_model.utils.build_tensor_info(Y_mini_batch)\n",
    "        tensor_info_predictions = tf.saved_model.utils.build_tensor_info(batch_predictions)         \n",
    "        \n",
    "    # Initialize all the variables\n",
    "    init_global_var = tf.global_variables_initializer() \n",
    "    \n",
    "    # sess is created fo the training phase\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(init_global_var)\n",
    "\n",
    "        sess.run(set_input_norm_mu)\n",
    "        sess.run(set_input_norm_sigma_square)\n",
    "        \n",
    "        epoch_nr = 0\n",
    "        for _ in range(NUM_TRAIN_EPOCHS // EPOCH_PERIOD_TO_SAVE_COST): \n",
    "            # Train EPOCH_PERIOD_TO_SAVE_COST epochs. Then validate train set. Then validate dev set.\n",
    "            for _ in range(EPOCH_PERIOD_TO_SAVE_COST):\n",
    "                sum_minibatch_costs = 0\n",
    "                nr_of_minibatches = 0\n",
    "                sess.run(tf_metrics_vars_initializer)  # initialize local_vars in tf.metrics\n",
    "                sess.run(iterator.initializer, feed_dict={filenames: TRAIN_INPUT_PATHS})\n",
    "                while True:\n",
    "                    try:\n",
    "                      _ , minibatch_cost, _ = sess.run([optimizer, \n",
    "                                                       cost_mini_batch, \n",
    "                                                       accuracy_update],\n",
    "                                                       feed_dict={training: True})\n",
    "                      nr_of_minibatches += 1\n",
    "                      sum_minibatch_costs += minibatch_cost                   \n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                      epoch_nr += 1\n",
    "                      #print(\"Out of range error triggered (looped through training set 1 time)\")\n",
    "                      break\n",
    "                    \n",
    "            # Note that cost and accuracy reporting is done on the entire train set, not based on a subset\n",
    "            current_cost_train = sum_minibatch_costs / nr_of_minibatches\n",
    "            costs_train.append(current_cost_train)\n",
    "            accuracies_train.append(sess.run(accuracy))\n",
    "            if PRINT_PROGRESS:\n",
    "                print (\"TRAIN: After epoch %i: Cost: %f   Accuracy: %f\" % \n",
    "                       (epoch_nr, current_cost_train, accuracies_train[-1]))\n",
    "            \n",
    "            \n",
    "            # BEfore continuing training...\n",
    "            # Now run validation on dev set to keep track of development (to later check bias/variance)\n",
    "\n",
    "            sum_minibatch_costs = 0\n",
    "            nr_of_minibatches = 0\n",
    "            sess.run(tf_metrics_vars_initializer)  # initialize local_vars in tf.metrics\n",
    "            sess.run(iterator.initializer, feed_dict={filenames: DEV_INPUT_PATHS})\n",
    "            while True:\n",
    "                try:\n",
    "                  minibatch_cost, _ = sess.run([cost_mini_batch, \n",
    "                                               accuracy_update],\n",
    "                                               feed_dict={training: False})\n",
    "                  nr_of_minibatches += 1\n",
    "                  sum_minibatch_costs += minibatch_cost\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                  #print(\"Out of range error triggered (looped through dev set 1 time only)\")\n",
    "                  break        \n",
    "            # Note that cost and accuracy reporting is done on the entire dev set, not based on a subset\n",
    "            current_cost_dev = sum_minibatch_costs / nr_of_minibatches\n",
    "            costs_dev.append(current_cost_dev)\n",
    "            accuracies_dev.append(sess.run(accuracy))\n",
    "            if PRINT_PROGRESS:\n",
    "                print (\"DEV:   After epoch %i: Cost: %f   Accuracy: %f\\n\" % \n",
    "                       (epoch_nr, current_cost_dev, accuracies_dev[-1]))\n",
    "\n",
    "            ##### SAVE THE MODEL - START ############\n",
    "            if SAVE_MODEL:\n",
    "                save_model(epoch_nr, tensor_info_filenames, tensor_info_training, tensor_info_input_IDs, \n",
    "                           tensor_info_X_mb, tensor_info_Y_mb, tensor_info_predictions, iterator.initializer)\n",
    "            ##### SAVE THE MODEL - END   ############            \n",
    "            \n",
    "        parameters = sess.run(parameters)\n",
    "        \n",
    "        ############## EVALUATE MODEL ON TEST SET --- START ##################\n",
    "        # Training is completed at this point.\n",
    "        #Calculate test set cost & accuracy. Improving test set cost is not the target here.Just further information..\n",
    "        sum_minibatch_costs = 0\n",
    "        nr_of_minibatches = 0\n",
    "        sess.run(tf_metrics_vars_initializer)  # initialize local_vars in tf.metrics\n",
    "        sess.run(iterator.initializer, feed_dict={filenames: TEST_INPUT_PATHS})\n",
    "        while True:\n",
    "            try:\n",
    "              minibatch_cost, _ = sess.run([cost_mini_batch, \n",
    "                                           accuracy_update],\n",
    "                                           feed_dict={training: False})\n",
    "              nr_of_minibatches += 1\n",
    "              sum_minibatch_costs += minibatch_cost\n",
    "            except tf.errors.OutOfRangeError:\n",
    "              #print(\"Out of range error triggered (looped through test set 1 time only)\")\n",
    "              break   \n",
    "        cost_test = sum_minibatch_costs / nr_of_minibatches\n",
    "        print(\"TEST: Cost: %f   --   Accuracy: %f\\n\" % (cost_test, sess.run(accuracy)))\n",
    "        ############## EVALUATE MODEL ON TEST SET --- END   ##################\n",
    "        \n",
    "        #### PRECISION - RECALL - F1 SCORE ---- START   #########\n",
    "        paths = {\"0\": TRAIN_INPUT_PATHS, \"1\": DEV_INPUT_PATHS, \"2\": TEST_INPUT_PATHS}\n",
    "        \n",
    "        for index in range(len(paths)):\n",
    "            sess.run(tf_metrics_vars_initializer)  # initialize local_vars in tf.metrics\n",
    "            sess.run(iterator.initializer, feed_dict={filenames: paths[str(index)]})\n",
    "            while True:\n",
    "                try:\n",
    "                  Y_mb, pred = sess.run([Y_mini_batch, batch_predictions], feed_dict={training: False}) \n",
    "\n",
    "                  for k in range (NUM_CLASSES):\n",
    "                    # If a given batch_labels = [[0],[0],[0],[1],[1],[2]]\n",
    "                    # then the following code will produce: [[True],[True],[True],[False],[False],[False]] for class_0  \n",
    "                    feed_labels =      np.equal(Y_mb, np.ones(Y_mb.shape)*k)\n",
    "                    feed_predictions = np.equal(pred, np.ones(pred.shape)*k)\n",
    "\n",
    "                    # Update precision and recall for the class=k\n",
    "                    sess.run([update_precision_per_class[k], update_recall_per_class[k]], \n",
    "                             feed_dict={tf_labels: feed_labels, \n",
    "                                        tf_predictions: feed_predictions})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                  #print(\"Out of range error triggered (looped through train set 1 time only)\")\n",
    "                  break   \n",
    "\n",
    "            # CALCULATE F1 SCORE PER CLASS. All 3 operations are element-wise\n",
    "            f1_numerator = tf.multiply(2., tf.multiply(precision_per_class, recall_per_class))\n",
    "            f1_denominator= tf.add(precision_per_class, recall_per_class)\n",
    "            f1_score_per_class = tf.divide(f1_numerator, f1_denominator)\n",
    "            print(\"F1 SCORE - SUMMARY for :\", paths[str(index)])\n",
    "            for k in range (NUM_CLASSES):    # NUM_UNITS_IN_LAYERS[-1] = NUM_CLASSES\n",
    "                print(\"class: \", k,\n",
    "                      \"  Precision:  \", sess.run(precision_per_class[k]),\n",
    "                      \"  Recall: \", sess.run(recall_per_class[k]),\n",
    "                      \"  F1 Score: \", sess.run(f1_score_per_class[k]))\n",
    "\n",
    "        #### PRECISION - RECALL - F1 SCORE ---- END   #########\n",
    "        \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs_train))\n",
    "    plt.plot(np.squeeze(costs_dev))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    # Print the accuracy\n",
    "    plt.plot(np.squeeze(accuracies_train))\n",
    "    plt.plot(np.squeeze(accuracies_dev))\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"costs_train\")\n",
    "    print(costs_train)\n",
    "    print(\"costs_dev\")\n",
    "    print(costs_dev)\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READS DATA FROM train data set CSV FILES, calculates mean (mu) and variance (sigma_square) for all features\n",
    "\n",
    "def get_input_norm_params(NORMALIZE_INPUT):\n",
    "    \n",
    "    if NORMALIZE_INPUT:\n",
    "\n",
    "        with tf.name_scope(\"next_train_batch\"):\n",
    "            filenames = tf.placeholder(tf.string, shape=[None])\n",
    "            dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "            dataset = dataset.flat_map(lambda filename: tf.data.TextLineDataset(filename).skip(1).map(decode_csv))\n",
    "            dataset = dataset.batch(MINIBATCH_SIZE)\n",
    "            iterator = dataset.make_initializable_iterator()\n",
    "            next_element = iterator.get_next()\n",
    "\n",
    "        num_examples = 0    # will keep total # train examples\n",
    "        mu = 0              # will keep mean of all feature values\n",
    "        sigma_square = 0    # keeps variance (to be used for scaling)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(iterator.initializer, feed_dict={filenames: TRAIN_INPUT_PATHS})\n",
    "            while True:\n",
    "                try:\n",
    "                  input_id, features, labels = sess.run(next_element)\n",
    "\n",
    "                  num_examples += features.shape[0] #size of axis=0 gives # train examples in the current batch\n",
    "\n",
    "                  # mu = sum_i(features) / num_train_examples  (where i = 1, .., num_train_examples)\n",
    "                  mu += tf.reduce_sum(features, axis=[0], keepdims=True)\n",
    "                  # sigma_square = sum_i(features ** 2) / num_train_examples  (where i = 1, .., num_train_examples)\n",
    "                  sigma_square +=  tf.reduce_sum(tf.multiply(features, features), axis=[0], keepdims=True)\n",
    "\n",
    "                  #print(sess.run(mu))\n",
    "                  #print(sess.run(sigma_square))\n",
    "\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                  print(\"Input normalization completed on train set data.\")\n",
    "                  break\n",
    "\n",
    "            mu /= num_examples\n",
    "            sigma_square /= num_examples\n",
    "            mu_return = sess.run(mu)\n",
    "            sigma_square_return = sess.run(sigma_square)\n",
    "    \n",
    "            #print(\"mu: \\n\", sess.run(mu))\n",
    "            #print(\"sigma: \\n\", sess.run(sigma_square))\n",
    "\n",
    "    else:\n",
    "        # If mu=0 and sigma_square=1, this means that input normalization NOT USED!\n",
    "        mu_return = 0.\n",
    "        sigma_square_return = 1.\n",
    "    \n",
    "    return mu_return, sigma_square_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input normalization completed on train set data.\n",
      "TRAIN: After epoch 10: Cost: 0.218754   Accuracy: 0.909091\n",
      "DEV:   After epoch 10: Cost: 2.512120   Accuracy: 0.800000\n",
      "\n",
      "TRAIN: After epoch 20: Cost: 0.114580   Accuracy: 0.977273\n",
      "DEV:   After epoch 20: Cost: 2.221195   Accuracy: 0.900000\n",
      "\n",
      "TRAIN: After epoch 30: Cost: 0.084702   Accuracy: 0.977273\n",
      "DEV:   After epoch 30: Cost: 1.494645   Accuracy: 0.900000\n",
      "\n",
      "TRAIN: After epoch 40: Cost: 0.075207   Accuracy: 0.977273\n",
      "DEV:   After epoch 40: Cost: 1.162389   Accuracy: 0.900000\n",
      "\n",
      "TRAIN: After epoch 50: Cost: 0.070500   Accuracy: 0.977273\n",
      "DEV:   After epoch 50: Cost: 1.225387   Accuracy: 0.900000\n",
      "\n",
      "TRAIN: After epoch 60: Cost: 0.068610   Accuracy: 0.977273\n",
      "DEV:   After epoch 60: Cost: 1.355243   Accuracy: 0.900000\n",
      "\n",
      "TRAIN: After epoch 70: Cost: 0.068893   Accuracy: 0.977273\n",
      "DEV:   After epoch 70: Cost: 0.606654   Accuracy: 0.900000\n",
      "\n",
      "TRAIN: After epoch 80: Cost: 0.068315   Accuracy: 0.977273\n",
      "DEV:   After epoch 80: Cost: 0.473381   Accuracy: 0.900000\n",
      "\n",
      "TEST: Cost: 1.348497   --   Accuracy: 0.750000\n",
      "\n",
      "F1 SCORE - SUMMARY for : ['train1.csv', 'train2.csv']\n",
      "class:  0   Precision:   0.8333333   Recall:  0.95238096   F1 Score:  0.8888889\n",
      "class:  1   Precision:   0.95   Recall:  0.82608694   F1 Score:  0.88372093\n",
      "F1 SCORE - SUMMARY for : ['dev1.csv']\n",
      "class:  0   Precision:   1.0   Recall:  0.6666667   F1 Score:  0.8\n",
      "class:  1   Precision:   0.875   Recall:  1.0   F1 Score:  0.93333334\n",
      "F1 SCORE - SUMMARY for : ['test1.csv']\n",
      "class:  0   Precision:   0.8181818   Recall:  0.75   F1 Score:  0.78260875\n",
      "class:  1   Precision:   0.6666667   Recall:  0.75   F1 Score:  0.7058823\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costs_train\n",
      "[0.21875385319193205, 0.11458015472938617, 0.08470167716344197, 0.07520651972542207, 0.07050021885273357, 0.06861014892153132, 0.06889270159687537, 0.06831496513526265]\n",
      "costs_dev\n",
      "[2.51212041079998, 2.22119471617043, 1.494645070284605, 1.1623891023918986, 1.2253869557753205, 1.355242582038045, 0.6066543813794851, 0.47338089905679226]\n",
      "{'W1': array([[ 0.07387052,  0.4030977 ,  0.41562936,  0.38670412,  0.9809736 ],\n",
      "       [ 0.3200123 ,  0.1333743 ,  1.3472292 ,  0.7712146 ,  0.83970094],\n",
      "       [-0.11868688, -0.26299247, -2.3210666 ,  0.7594114 , -0.33426076],\n",
      "       [ 0.14178206,  0.04377748, -0.6666176 , -0.07996884,  0.6407589 ],\n",
      "       [-0.19794968,  0.2890996 ,  0.89487666,  1.2388511 ,  0.3175077 ],\n",
      "       [ 0.25090635,  0.12249519,  1.286142  ,  0.41519284,  0.72328115]],\n",
      "      dtype=float32), 'b1': array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), 'W2': array([[-2.6476133, -1.8111415,  1.0054271, -0.8142091, -1.5436779,\n",
      "        -0.5651785],\n",
      "       [ 1.4056052,  0.6704971, -1.8960817,  1.2211694,  0.7422964,\n",
      "         1.5287019]], dtype=float32), 'b2': array([[0.],\n",
      "       [0.]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# NOTE1: Whenever you need to use the framework, you need to update the list of record_defaults that defines\n",
    "# default values for empty cells in the csv file. Go to decode_csv file to update it.\n",
    "# NOTE2: Only numerical data is supported right now in the excel file.\n",
    "\n",
    "# RUN AND TRAIN THE MODEL...\n",
    "\n",
    "mu, sigma_square = get_input_norm_params(NORMALIZE_INPUT)\n",
    "\n",
    "parameters = nn_model(mu, sigma_square)\n",
    "\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "# Implement accuracy calculation (on train and test sets)  -- DONE!\n",
    "# Implement using CSV file(s) even for test data to calculate test accuracy  - DONE!\n",
    "# Add batch normalization   -- DONE!\n",
    "# Dropout   -- DONE!\n",
    "# Add normalization to input params in layer=0  -- DONE!\n",
    "# For softmax classification particularly, let label be 1 single column and generate the corresponding Y vectors dynamically \n",
    "# in the program -- DONE!\n",
    "# Learning decay -- DONE!\n",
    "# Accuracy calculation updated with tf.metrics.accuracy() -- DONE!\n",
    "# Implement F1 Score, Precision, and Recall PER CLASS (num_classes can be more than 2)  -- DONE!\n",
    "# Can we use tf.layers.dense(...) for forward propagation?\n",
    "# Check tensorboard and if you have given appropriate names to your tensors\n",
    "# Can we use ELU instead of RELU? ELU function has a parameter called alpha that needs to be tuned. The common \n",
    "# practice for ELU is to set alpha to 1. (Probably changing it doesnt give that much gain)\n",
    "# Implement a new program that restores the latest model, takes an input and makes a prediction\n",
    "\n",
    "\n",
    "abc = []\n",
    "abc.append(1)\n",
    "abc.append(5)\n",
    "print(abc)\n",
    "print(sum(abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "der = np.array([3,3,3])\n",
    "print(len(der))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
